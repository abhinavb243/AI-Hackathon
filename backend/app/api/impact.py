from fastapi import APIRouter, HTTPException, Body
from pydantic import BaseModel
from datetime import datetime
from typing import List, Dict, Any, Optional
from app.core.supabase_client import supabase
import json
import os
from langchain_openai import ChatOpenAI
from app.core.settings import OPENAI_API_KEY

router = APIRouter(prefix="/impact")

class ImpactAssessment(BaseModel):
    regulation_diff_id: str
    findings: List[Dict[str, Any]]
    exposures: List[Dict[str, Any]]
    severity: str
    impact_areas: List[str]
    estimated_cost: Optional[float] = None

class ComplianceAssessmentRequest(BaseModel):
    regulation_diff_id: str
    use_mock_data: bool = False

@router.post("/assess/{regulation_diff_id}")
async def assess_impact(regulation_diff_id: str):
    """Assess financial impact of a specific regulation diff"""
    try:
        # Get the regulation diff from Supabase
        reg_diff_result = supabase.table("regulation_diffs") \
                                .select("*") \
                                .eq("id", regulation_diff_id) \
                                .execute()
        
        if not reg_diff_result.data:
            raise HTTPException(status_code=404, detail="Regulation diff not found")
        
        regulation_diff = reg_diff_result.data[0]
        
        # Get relevant data catalog entries for context
        data_catalog_result = supabase.table("data_catalog") \
                                    .select("*") \
                                    .limit(10) \
                                    .execute()
        
        data_catalog = data_catalog_result.data
        
        # In a real implementation, we would use LangGraph and agent here
        # For now, we simulate the Financial Impact Assessment agent

        # Initialize LLM (would be part of LangGraph in full implementation)
        llm = ChatOpenAI(api_key=OPENAI_API_KEY, model="gpt-4o")
        
        # Simulated findings
        findings = [
            {
                "id": "finding-001",
                "title": "Quarterly reporting threshold change impacts 15 funds",
                "description": "The change in threshold from $1B to $500M means 15 additional funds will need quarterly reporting",
                "regulation_section": "2a",
                "confidence": 0.92
            },
            {
                "id": "finding-002",
                "title": "New disclosure requirements affect investment strategy reporting",
                "description": "All private funds will need to update reporting templates and processes",
                "regulation_section": "4b",
                "confidence": 0.85
            }
        ]
        
        # Simulated exposures
        exposures = [
            {
                "id": "exposure-001",
                "financial_impact": 250000,
                "description": "Estimated cost for implementing new reporting systems and processes",
                "affected_departments": ["Operations", "Compliance", "IT"],
                "timeframe": "6 months"
            }
        ]
        
        # Create impact assessment
        impact_assessment = {
            "regulation_diff_id": regulation_diff_id,
            "findings": findings,
            "exposures": exposures,
            "severity": "Medium",
            "impact_areas": ["Reporting", "Operations", "Compliance"],
            "estimated_cost": 250000,
            "created_at": datetime.now().isoformat()
        }
        
        # Insert into Supabase
        result = supabase.table("findings").insert(impact_assessment).execute()
        
        return {
            "status": "success",
            "message": "Impact assessment completed",
            "impact_assessment": impact_assessment
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error assessing impact: {str(e)}")

@router.post("/assess-compliance")
async def assess_compliance(request: ComplianceAssessmentRequest):
    """
    Assess compliance by comparing regulation requirements with company data practices
    This endpoint uses the AI agent to detect non-compliances between regulations and practices
    """
    try:
        # Get the regulation diff from Supabase
        regulation_diff = None
        try:
            if supabase:
                reg_diff_result = supabase.table("regulation_diffs") \
                                      .select("*") \
                                      .eq("id", request.regulation_diff_id) \
                                      .execute()
                regulation_diff = reg_diff_result.data[0] if reg_diff_result.data else None
        except Exception as db_error:
            print(f"Database error fetching regulation (using mock): {str(db_error)}")
            
        # If we couldn't get from database or database not available, use mock data
        if not regulation_diff:
            regulation_diff = {
                "source": "GDPR",
                "title": "Mock GDPR Regulation",
                "summary": "Mock regulation data for testing"
            }
        
        # Get company data handling practices from data catalog
        data_catalog = None
        try:
            if supabase:
                data_catalog_result = supabase.table("data_catalog") \
                                          .select("*") \
                                          .execute()
                data_catalog = data_catalog_result.data
        except Exception as db_error:
            print(f"Database error fetching data catalog: {str(db_error)}")
        
        if not data_catalog:
            # If no real data practices are found and mock data is requested
            if request.use_mock_data:
                # Use mock data practices for testing
                data_catalog = [
                    {
                        "id": "mock-1",
                        "name": "Customer Personal Information",
                        "data_type": "PII",
                        "description": "Customer names, addresses, phone numbers, email addresses",
                        "storage_location": "CRM Database",
                        "classification": "Confidential",
                        "retention_period": "5 years after last activity",
                        "access_controls": "Role-based, restricted to Customer Service",
                        "processing_purpose": "Customer Support, Sales"
                    },
                    {
                        "id": "mock-2",
                        "name": "Payment Information",
                        "data_type": "Financial PII",
                        "description": "Credit card numbers, bank account details",
                        "storage_location": "Payment Processing System",
                        "classification": "Restricted",
                        "retention_period": "3 years after last transaction",
                        "access_controls": "Minimal access, encrypted",
                        "processing_purpose": "Transaction Processing"
                    },
                    {
                        "id": "mock-3",
                        "name": "User Browsing History",
                        "data_type": "Behavioral",
                        "description": "Pages visited, time spent, clicks",
                        "storage_location": "Analytics Database",
                        "classification": "Internal",
                        "retention_period": "2 years",
                        "access_controls": "Marketing Team",
                        "processing_purpose": "Product Improvement, Marketing"
                    }
                ]
            else:
                raise HTTPException(status_code=404, detail="No company data practices found in data catalog")
        
        # Skip LLM call for testing - we don't need an actual OpenAI key
        # Just generate mock findings
        
        # Extract regulation source to customize findings
        regulation_source = regulation_diff.get("source", "GDPR")
        
        findings = []
        
        # Generate findings based on the regulation source
        if regulation_source == "GDPR":
            # Check for data retention issues
            for data_item in data_catalog:
                # Simulate finding long retention periods that might violate GDPR
                if (data_item.get("retention_period") and 
                    ("indefinite" in data_item.get("retention_period").lower() or
                     "permanent" in data_item.get("retention_period").lower() or
                     "years" in data_item.get("retention_period").lower() and "5 years" in data_item.get("retention_period"))):
                    findings.append({
                        "id": f"finding-{len(findings)+1}",
                        "title": f"Excessive retention period for {data_item.get('name')}",
                        "description": f"Data is kept for {data_item.get('retention_period')} which exceeds GDPR's data minimization principles",
                        "regulation_section": "Article 5(1)(e)",
                        "confidence": 0.88,
                        "data_catalog_id": data_item.get("id"),
                        "remediation": "Review and implement shorter retention periods based on actual business needs"
                    })
                
                # Check if purpose limitation is clear
                if not data_item.get("processing_purpose") or data_item.get("processing_purpose") == "":
                    findings.append({
                        "id": f"finding-{len(findings)+1}",
                        "title": f"Missing purpose specification for {data_item.get('name')}",
                        "description": "Processing purpose is not clearly defined, violating GDPR purpose limitation principle",
                        "regulation_section": "Article 5(1)(b)",
                        "confidence": 0.92,
                        "data_catalog_id": data_item.get("id"),
                        "remediation": "Clearly define and document the specific purposes for processing this data"
                    })
                
                # Check for appropriate security measures
                if not data_item.get("access_controls") or data_item.get("access_controls") == "":
                    findings.append({
                        "id": f"finding-{len(findings)+1}",
                        "title": f"Inadequate access controls for {data_item.get('name')}",
                        "description": "No defined access controls, violating GDPR security requirements",
                        "regulation_section": "Article 32",
                        "confidence": 0.85,
                        "data_catalog_id": data_item.get("id"),
                        "remediation": "Implement appropriate access controls based on least privilege principle"
                    })
        elif regulation_source == "CCPA":
            # Sample CCPA-specific findings
            for data_item in data_catalog:
                # Check if there's a clear retention period
                if not data_item.get("retention_period"):
                    findings.append({
                        "id": f"finding-{len(findings)+1}",
                        "title": f"Missing retention period for {data_item.get('name')}",
                        "description": "CCPA requires clear disclosure of retention periods for each category of personal information",
                        "regulation_section": "1798.130(a)(5)(B)",
                        "confidence": 0.87,
                        "data_catalog_id": data_item.get("id"),
                        "remediation": "Define and document retention periods for this data category"
                    })
        
        # Calculate severity and financial impact based on findings
        severity = "Low"
        if len(findings) > 5:
            severity = "High"
        elif len(findings) > 2:
            severity = "Medium"
        
        # Estimate financial impact (in a real system, this would be more sophisticated)
        estimated_cost = len(findings) * 50000  # Simple estimate: $50K per finding
        
        # Create impact areas list
        impact_areas = ["Data Governance", "Compliance"]
        if any("security" in finding.get("title").lower() for finding in findings):
            impact_areas.append("Security")
        if any("retention" in finding.get("title").lower() for finding in findings):
            impact_areas.append("Data Management")
        
        # Create exposures
        exposures = [
            {
                "id": "exposure-001",
                "financial_impact": estimated_cost,
                "description": f"Estimated cost for remediating {len(findings)} compliance issues",
                "affected_departments": ["Legal", "Compliance", "IT"],
                "timeframe": "3 months"
            }
        ]
        
        # Add statutory penalty exposure for high severity findings
        if severity == "High":
            if regulation_source == "GDPR":
                exposures.append({
                    "id": "exposure-002",
                    "financial_impact": 20000000,  # 20 million euros or 4% of global turnover
                    "description": "Potential GDPR penalty (up to â‚¬20M or 4% of global annual turnover)",
                    "affected_departments": ["Executive", "Legal", "Finance"],
                    "timeframe": "Immediate risk"
                })
            elif regulation_source == "CCPA":
                exposures.append({
                    "id": "exposure-002",
                    "financial_impact": 7500 * 1000,  # $7,500 per violation, assuming 1000 consumers affected
                    "description": "Potential CCPA penalties ($7,500 per intentional violation)",
                    "affected_departments": ["Executive", "Legal", "Finance"],
                    "timeframe": "Immediate risk"
                })
        
        # Create impact assessment
        impact_assessment = {
            "regulation_diff_id": request.regulation_diff_id,
            "findings": findings,
            "exposures": exposures,
            "severity": severity,
            "impact_areas": impact_areas,
            "estimated_cost": estimated_cost,
            "created_at": datetime.now().isoformat()
        }
        
        # Try to insert into Supabase, but continue if it fails
        try:
            if supabase:
                result = supabase.table("findings").insert(impact_assessment).execute()
        except Exception as db_error:
            print(f"Database error inserting findings (continuing): {str(db_error)}")
        
        return {
            "status": "success",
            "message": f"Compliance assessment completed. Found {len(findings)} issues.",
            "impact_assessment": impact_assessment
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error assessing compliance: {str(e)}")

@router.get("/findings")
async def get_findings():
    """Get all impact assessment findings"""
    try:
        result = supabase.table("findings").select("*").execute()
        return result.data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error fetching findings: {str(e)}") 